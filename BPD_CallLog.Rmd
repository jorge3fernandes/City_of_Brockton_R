---
title: "Brockton Police Call Log Research"
author: "Jorge Fernandes"
date: "February 7, 2016"
output: html_document
---


By inpecting the  website, you can see that the data is presented in an archive by date. Noticing that will make our extraction easier. we will just manipulate the URL to make it go through the whole archive.
```{r}
library(plyr)
library(RCurl)
library(stringr)
library(pdftools)
library(dplyr)
library(ggmap)
library(ggplot2)
library(maps)
library(googleVis)
library(sp)
library(data.table)
library(plotly)
library(rjson)
library(leaflet)
library(magrittr)
library(jsonlite)
library(dygraphs)
library(lubridate)
library(xts)
library(RDSTK)
library(mondate)
```


By examining the urls, sometimes there is no leading zero before days and months less than ten.  
I also noticed that for some days, the months in the URL are different.
Some of the links have the four digits year spelled out.

Here I'm creating all the urls with leading zeros where days and months are less than ten.

```{r}

prefix <- "http://www.brocktonpolice.com/wp-content/uploads/"
AllDays <- seq.Date(from = as.Date('2015-04-01'), to = Sys.Date(), by = "day")
backdays <- AllDays - 30
#Here I'm creating all the urls with without leading zeros where days and months are less than ten.
AllDays_NL <- gsub("0", "", format(AllDays, '%m%d%y'))
AllDays_NL_5 <- gsub("0", "", format(backdays, '%m%d%y'))
links1 <- paste0(prefix, format(AllDays, '%Y/%m/%m%d%y'), '.pdf')
links2 <- paste0(prefix, format(AllDays, '%Y/%m/'), AllDays_NL,'.pdf')
links3 <- paste0(prefix, format(AllDays, '%Y/%m/%m%d%Y'), '.pdf')
links4 <- paste0(prefix, format(AllDays, '%Y/%m/'), format(backdays,"%m%d%y"),'.pdf')
links5 <- paste0(prefix, format(AllDays, '%Y/%m/'), AllDays_NL_5,'.pdf')

links <- c(links1,links2,links3, links4, links5)
```

Here, we go against the website and download the data.

```{r , eval= FALSE, error= FALSE}

#assiging a new WD to put the PDFs
folder <- paste0(getwd(),"/","Police_logs")
filenames <- str_c(format(seq.Date(from = as.Date("2015-04-01"), 
                                   to = Sys.Date(), by = "day"),"%Y_%m_%d"),".pdf")
filenames_Total <- c(filenames,filenames,filenames,filenames,filenames)
setwd(folder)

test <- data.frame(filenames_Total,links)

for (i in seq_along(links4)) {
      #using trycatch to bipass the error when url doesn't exist
      tryCatch({
      if (!file.exists(str_c(folder,"/",filenames[i]))) { 
                  download.file(links4[i], filenames[i], mode = "wb")
          print(paste0("Downloading: ", filenames[i]))
      } },error = function(e){}
      
      )
      
      #since we bipassed the error and the file was created anyway, we go in and  
      #check for file size to make sure the file is deleted before the loop checks
      #checks for file name again
      if (is.na(file.info(filenames[i])$size) | file.info(filenames[i])$size == 0) {
            file.remove(filenames[i])}
}
##########################################ALTERNANTE DOWNLOAD########################
for (i in seq_along(links)) {
      #using trycatch to bipass the error when url doesn't exist
      tryCatch({
                  download.file(links[i],paste0("file_",i,".pdf") , mode = "wb")
          print(paste0("Downloading: ", paste0("file_",i,".pdf")))
       },error = function(e){}
      
      )
      
      #since we bipassed the error and the file was created anyway, we go in and  
      #check for file size to make sure the file is deleted before the loop checks
      #checks for file name again
      if (is.na(file.info(paste0("file_",i,".pdf"))$size) | file.info(paste0("file_",i,".pdf"))$size == 0) {
            file.remove(paste0("file_",i,".pdf"))}
}

# Checking for missing files
Missingfilenames <- filenames[which(!(filenames%in%pdf_list))]
missing_links <- links4[which(!(filenames%in%pdf_list))]
test <- data.frame(Missingfilenames,missing_links)

```

Since the data is in pdf format, we use pdftools to extract text from the PDFs

```{r , eval= FALSE, error= FALSE}
# I use PDFtools to extract text from PDF

pdf_list <- list.files(path = folder,
                       pattern = ".pdf")



txt_names <- list.files(path = folder,
                       pattern = ".pdf") %>% str_replace_all(".pdf",".txt")

i <- 1
for (i in seq_along(txt_names)) {
            if (!file.exists(folder[i])) { 
                  write(pdf_text(pdf_list[i]), file = txt_names[i])
              print(paste("Working on file: ",pdf_list[i]))
            }
           
}

txt_names <- list.files(folder, pattern = ".txt")

folder[2]

```

Processing texts

```{r , eval= FALSE, error= FALSE}
 df <- function(txt_names[111]) {
                    text <- readLines("file_111.txt")
  
                    #marking where to split
  
                    for (i in seq_along(text)) { 
        
                          if (str_detect(text[i],'                [[:digit:]]{4}')) { 
                                text[i] <- paste0("CALL BEGINS HERE",text[i] )
                                }
  
                          }
  
  
                    txt <- str_c(text, collapse = "\n")
  
                    #split the text by calls
                    txtparts <- unlist(str_split(txt, "CALL BEGINS HERE"))
  
                    #extracting specific fields
                    Time <- str_trim(str_extract(txtparts, "                [[:digit:]]{4}")) 
                    Time <- sub("(..)$", ":\\1", Time) 

                    date <- rep(str_extract(txtparts[1], "\\d{2}/\\d{2}/\\d{4}"),length(Time))
                    Date <- paste0(date," ",Time)
                    
                    Call_taker <- str_replace_all(str_extract(txtparts, "Call Taker:.*\n"),"Call Taker:","" ) %>% str_replace_all("\n","")
                    
                    


                    Response_address <- str_extract(txtparts, "Location/Address:.*\n|Vicinity of:.*\n")%>% str_replace_all("Location/Address:|Vicinity of:","") %>% str_replace_all("\n","") %>% paste0( ", BROCKTON, MA") %>% str_replace_all("\\[BRO.*\\]","") %>% str_replace_all(" EXT, ","") %>% str_replace_all(" SQ,", "SQUARE")
                    #Since I'm capturing only the raw data, I'll save the next steps for later
                   # address <- str_replace_all(address,' Apt\\. .*, ',', BROCKTON, ')
                   # address <- str_replace_all(address,"NA, BROCKTON, MA","")

                    police_officer <- str_extract_all(txtparts, "(?s)Location\\/Address:[^\n]*\\R(.*)|(?s)Vicinity of:[^\n]*\\R(.*)") %>%str_extract_all("ID:.*\n|Patrolman.*\n")
                    police_officer <-str_replace_all(police_officer,"ID:","") %>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    call_reason_action <- str_extract_all(txtparts, "                [[:digit:]]{4}.*\n")
                    call_reason_action <- str_replace_all(call_reason_action, "[[:digit:]]{4}","")%>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    Refer_To_Arrest <- str_extract(txtparts, "Refer To Arrest:.*\n") %>% str_replace_all("Refer To Arrest:","") 
                    
                    Refer_To_Summons <- str_extract_all(txtparts, "Refer To Summons:.*\n")
                    Refer_To_Summons <- str_replace_all(Refer_To_Summons, "Refer To Summons:","")%>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    Summons <- str_extract_all(txtparts, "         Summons:    .*\n") %>%str_replace_all("Summons:","")  
                    Summons <- str_replace_all(Summons, "c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    Arrested <- str_extract_all(txtparts, "          Arrest:    .*\n") 
                    Arrested <- str_replace_all(Arrested,"Arrest:","") %>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    Age <- str_extract_all(txtparts,"Age:.*\n") %>% str_replace_all("Age:","")
                    Age <- str_replace_all(Age, "c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    #age_m <- unlist(str_split(Age, ","))
                    
                    Suspect_Address <- str_extract_all(txtparts,"         Address:    .*\n") %>% str_replace_all("Address:","") 
                    Occurrence_location <- str_replace_all(Occurrence_location, "c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    charges <- unlist(str_extract_all(txtparts,"Charges:    .*\n")%>% str_replace_all("Charges:",""))
                    charges <- str_replace_all(charges, "c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    response_time <- str_extract_all(txtparts,"Arvd.*\n") 
                    response_time <- str_replace_all(response_time, "c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","") %>% str_replace_all("c\\(","")
  
  
                    #Putting everything together
  
                    BPD_log <- cbind(Date, Call_taker, call_reason_action, Response_address, police_officer, Refer_To_Summons, Summons, Refer_To_Arrest, Arrested,Age,  Suspect_Address, charges, response_time)
                    BPD_log <- data.frame(BPD_log, stringsAsFactors = FALSE)
                    BPD_log[BPD_log == "character(0"] = NA 
                    BPD_log[BPD_log == "character(0)"] = NA
                    BPD_log[BPD_log == ""] = NA 
                    BPD_log$Response_address[is.na(BPD_log$Response_address)] <- 0
                    BPD_log <- subset(BPD_log, !is.na(Call_taker))
                    BPD_log$Date <- as.POSIXct(BPD_log$Date,format ="%m/%d/%Y %H:%M", tz = "EST")
                    BPD_log$Month <- month(BPD_log$Date)
                    BPD_log$Day <- day(BPD_log$Date)

                    for ( i in seq_along(BPD_log$Summons)){
                      
                          if(!is.na(BPD_log$Summons[i])){
  
                            BPD_log$Arr_summ_ind[i] <- "Summoned"
                          } else
                            ifelse(!is.na(BPD_log$Refer_To_Arrest[i]),BPD_log$Arr_summ_ind[i] <- "Arrested",BPD_log$Arr_summ_ind[i] <- "Other")
                    }
                  
        return(BPD_log)
 }

for (i in seq_along(BPD_log$Age)){
  if (length(unlist(BPD_log$Age[174], ",")) > 1){
          temp <- unlist(BPD_log$Age[i]
    for (j in seq_along(temp)){
      
      BPD_log$Age_arrested() <- temp[j]
    }
  }
}


```

Combining daily logs into one data frame

```{r , eval= FALSE, error= FALSE}
Full_df <- df(txt_names[1])
i <- 2
while (i < length(txt_names)) {
      
      Full_df <- rbind(Full_df,df(txt_names[i])) 
      
      i = i + 1
} 

write.csv(Full_df, "full_bpd_calls.csv")
write.csv(Full_df[,c(1,4)], "address_bpd_calls.csv")
```

This will run after we have all the days merged
Geocoding script for large list of addresses   

Define a function that will process googles server responses for us.

```{r , eval= FALSE, error= FALSE}

GEO_Data$address_Geo <- as.character(GEO_Data$address_Geo)

GEO_Data$address_Geo[is.na(GEO_Data$address_Geo)] <- 0
getGeoDetails <- function(address_Geo){ 
     address_Geo <- as.character(address_Geo) 
   #use the gecode function to query google servers
   geo_reply = geocode(address_Geo, output='all', messaging=TRUE, override_limit=TRUE)
   #now extract the bits that we need from the returned list
   answer <- data.frame(lat = NA, 
                        long = NA, 
                        accuracy = NA, 
                        formatted_address = NA, 
                        address_type=NA, 
                        status=NA)
   answer$status <- geo_reply$status

   #if we are over the query limit - want to pause for an hour
   while(geo_reply$status == "OVER_QUERY_LIMIT"){
       print("OVER QUERY LIMIT - Pausing for 1 hour at:") 
       time <- Sys.time()
       print(as.character(time))
       Sys.sleep(60*60)
       geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
       answer$status <- geo_reply$status
   }

   #return Na's if we didn't get a match:
   if (geo_reply$status != "OK"){
       return(answer)
   }   
   #else, extract what we need from the Google server reply into a dataframe:
   answer$lat <- geo_reply$results[[1]]$geometry$location$lat
   answer$long <- geo_reply$results[[1]]$geometry$location$lng   
   if (length(geo_reply$results[[1]]$types) > 0){
       answer$accuracy <- geo_reply$results[[1]]$types[[1]]
   }
   answer$address_type <- paste(geo_reply$results[[1]]$types, collapse=',')
   answer$formatted_address <- geo_reply$results[[1]]$formatted_address

   return(answer)
}

#initialise a dataframe to hold the results
geocoded <- data.frame()
# find out where to start in the address list (if the script was interrupted before):
startindex <- 1
#if a temp file exists - load it up and count the rows!

infile <- "input99"

tempfilename <- paste0(infile, '_temp_geocoded.rds')
if (file.exists(tempfilename)){
       print("Found temp file - resuming from index:")
       geocoded <- readRDS(tempfilename)
       startindex <- nrow(geocoded)
       print(startindex)
}

# Start the geocoding process - address by address. geocode() function takes care of query speed limit.
for (ii in seq(startindex, length(GEO_Data$address_Geo ))){
   print(paste("Working on index", ii, "of", length(GEO_Data$address_Geo )))
   #query the google geocoder - this will pause here if we are over the limit.
   result = getGeoDetails(GEO_Data$address_Geo [ii]) 
   print(result$status)     
   result$index <- ii
   #append the answer to the results file.
   geocoded <- rbind(geocoded, result)
   #save temporary results as we are going along
   saveRDS(geocoded, tempfilename)
}

#now we add the latitude and longitude to the main data
CrimeData <- Full_df[!is.na(Full_df$Refer_To_Summons),]
testdata$lat <- geocoded$lat
testdata$long <- geocoded$long
testdata$accuracy <- geocoded$accuracy
testdata$formatted_address <- geocoded$formatted_address
testdata$Date <- as.POSIXct(testdata$Date,format ="%m/%d/%Y %H:%M", tz = "EST")
testdata$Month <-   month(testdata$Date, label = TRUE)
testdata$Day <- day(testdata$Date)
testdata <- subset(testdata, !is.na(Date))
testdata <- subset(testdata, formatted_address != "Olt County, Romania")

#finally write it all to the output files
saveRDS(Full_df, paste0("../data/", infile ,"_geocoded.rds"))
write.table(data, file=paste0("../data/", infile ,"_geocoded.csv"), sep=",", row.names=FALSE)


```
Test
```{r , eval= FALSE, error= FALSE}

pal <- colorFactor(c("green", "black","red"), domain = testdata$Arr_summ_ind)
mymap <- leaflet(data = testdata) %>% 
  addTiles() %>% 
  setView(-71.02016, 42.08667, zoom = 13) %>% 
  addMarkers(~ long, ~ lat, clusterOptions = markerClusterOptions(zoomToBoundsOnClick = TRUE)) 
mymap

# Creating a word cloud

library(tm)
library(SnowballC)
library(wordcloud)

BRCorpus <- Corpus(VectorSource(testdata$charges))
BRCorpus <- tm_map(BRCorpus, PlainTextDocument)
wordcloud(BRCorpus, max.words = 100, random.order = FALSE)



#trying to visualize patern on the frequency og calls by day or month
hits_hour = count(testdata, vars = hour(testdata$Date))

colnames(hits_hour) <- c("Hour","Calls")
hist <- ggplot(data = hits_hour) + geom_line(aes(x = Hour, y =  Calls)) 

library("rpivotTable")
rpivotTable(testdata)


call_volume <- tally(group_by(testdata, Date))

colnames(call_volume) <- c("Time", "Count")

ts <- as.xts(call_volume, order.by = call_volume$Date)
dygraph(ts, main = "Call Frequency", xlab = "Date", ylab = "Frequency")

```


```{r, eval= FALSE, error= FALSE}

check <- testdata$address


check <- geocode(Full_df$address[1:136], output='all', messaging=TRUE, override_limit=TRUE)
 check$lat <- check$results[[1]]$geometry$location$lat
   check$long <- check$results[[1]]$geometry$location$lng   
   if (length(check$results[[1]]$types) > 0){
       check$accuracy <- check$results[[1]]$types[[1]]
   }
   check$address_type <- paste(check$results[[1]]$types, collapse=',')
   check$formatted_address <- check$results[[1]]$formatted_address

   return(check)

test <- cbind(Full_df$address[1:length(check)], check)


set.seed(100)
d <- diamonds[sample(nrow(diamonds), 1000), ]
plot_ly(d, x = testdata$Date, y = price, text = paste("Clarity: ", clarity),
        mode = "markers", color = carat, size = carat)

```

