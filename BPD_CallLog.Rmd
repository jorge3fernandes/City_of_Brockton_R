---
title: "Brockton Police Call Log Research"
author: "Jorge Fernandes"
date: "February 7, 2016"
output: html_document
---


By inpecting the  website, you can see that the data is presented in an archive by date. Noticing that will make our extraction easier. we will just manipulate the URL to make it go through the whole archive.
```{r}

library(plyr)
library(RCurl)
library(stringr)
library(pdftools)
library(dplyr)
library(ggmap)
library(ggplot2)
library(maps)
library(googleVis)
library(sp)
library(data.table)
library(plotly)
library(leaflet)
library(magrittr)

```


By examining the urls, sometimes there is no leading zero before days and months less than ten.  

Here I'm creating all the urls with leading zeros where days and months are less than ten.

```{r}

prefix <- "http://brocktonpolice.com/wp-content/uploads/"
AllDays <- seq.Date(from = as.Date('2015-01-01'), to = Sys.Date(), by = "day")
links1 <- paste0(prefix, format(AllDays, '%Y/%m/%m%d%y'), '.pdf')

```

Here I'm creating all the urls with without leading zeros where days and months are less than ten.

```{r}

AllDays_NL <- gsub("0", "", format(AllDays, '%m%d%y'))
links2 <- paste0(prefix, format(AllDays, '%Y/%m/'), AllDays_NL,'.pdf')

```

Since there is not a clear pattern on when we do and don't have a leading zero, we will put the two lists together and extract the data whenever we have a match
```{r , eval= FALSE, error= FALSE}

link <- c(links1,links2)

```

Here, we go against the website and download the data.

```{r , eval= FALSE, error= FALSE}
#assiging a new WD to put the PDFs
folder <- paste0(getwd(),"/","Police_logs")
filenames <- str_c(format(seq.Date(from = as.Date("2015-01-01"), 
                                   to = Sys.Date(), by = "day"),"%Y_%m_%d"),".pdf")
filenames <- c(filenames,filenames)

setwd(folder)
for (i in seq_along(link)) {
      #using trycatch to bipass the error when url doesn't exist
      tryCatch({
      if (!file.exists(str_c(folder,"/",filenames[i]))) { 
                  download.file(link[91], filenames[91], mode = "wb")
                  } }, error = function(e){})
      #since we bipassed the error and the file was created anyway, we go in and  
      #check for file size to make sure the file is deleted before the loop checks
      #checks for file name again
      if (is.na(file.info(filenames[i])$size) | file.info(filenames[i])$size == 0) {
            file.remove(filenames[i])
      }
      
}

```

Since the data is in pdf format, we use pdftools to extract text from the PDFs

```{r , eval= FALSE, error= FALSE}
# I use PDFtools to extract text from PDF

pdf_list <- list.files(path = folder,
                       pattern = ".pdf",
                       full.names = TRUE)

txt_names <- list.files(folder, pattern = "pdf") %>% str_replace(".pdf",".txt")

for (i in seq_along(txt_names)) {
            if (!file.exists(folder[i])) { 
                  write(pdf_text(pdf_list[i]), file = txt_names[i])
            }
           
}

```

Processing texts

```{r , eval= FALSE, error= FALSE}
 df <- function(call_log) {
                    text <- readLines(call_log)
  
                    #marking where to split
  
                    for (i in seq_along(text)) { 
        
                          if (str_detect(text[i],'                [[:digit:]]{4}')) { 
                                text[i] <- paste0("CALL BEGINS HERE",text[i] )
                                }
  
                          }
  
  
                    txt <- str_c(text, collapse = "\n")
  
                    #split the text by calls
                    txtparts <- unlist(str_split(txt, "CALL BEGINS HERE"))
  
                    #extracting specific fields
                    Time <- str_trim(str_extract(txtparts, "                [[:digit:]]{4}")) 
                    Time <- sub("(..)$", ":\\1", Time) 

                    date <- rep(str_extract(txtparts[1], "\\d{2}/\\d{2}/\\d{4}"),length(Time))
                    Date <- paste0(date," ",Time)
                    
                    Call_taker <- str_replace_all(str_extract(txtparts, "Call Taker:.*\n"),"Call Taker:","" ) %>% str_replace_all("\n","")
                    
                    
                    
                    address <- str_extract(txtparts, "Location/Address:.*\n|Vicinity of:.*\n")%>% str_replace_all("Location/Address:|Vicinity of:","") %>% str_replace_all("\n","") %>% paste0( ", BROCKTON, MA") %>% str_replace_all("\\[BRO.*\\]","")
                    address <- str_replace_all(address,"NA.*MA","")
                    
                    police_officer <- str_extract_all(txtparts, "(?s)Location\\/Address:[^\n]*\\R(.*)|(?s)Vicinity of:[^\n]*\\R(.*)") %>%str_extract_all("ID:.*\n|Patrolman.*\n") %>% str_replace_all("ID:","") %>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    call_reason_action <- str_extract_all(txtparts, "                [[:digit:]]{4}.*\n")%>% str_replace_all("[[:digit:]]{4}","")%>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    Refer_To_Arrest <- str_extract(txtparts, "Refer To Arrest:.*\n") %>% str_replace_all("Refer To Arrest:","") 
                    
                    Refer_To_Summons <- str_extract_all(txtparts, "Refer To Summons:.*\n") %>% str_replace_all("Refer To Summons:","")%>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    Summons <- str_extract_all(txtparts, "         Summons:    .*\n")  %>% str_replace_all("Summons:","") %>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    Arrested <- str_extract_all(txtparts, "          Arrest:    .*\n")  %>% str_replace_all("Arrest:","") %>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    Age <- str_extract_all(txtparts,"Age:.*\n") %>% str_replace_all("Age:","") %>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    Occurrence_location <- str_extract_all(txtparts,"         Address:    .*\n") %>% str_replace_all("Address:","") %>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    charges <- unlist(str_extract_all(txtparts,"Charges:    .*\n")%>% str_replace_all("Charges:","")) %>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","")
                    
                    response_time <- str_extract_all(txtparts,"Arvd.*\n") %>% str_replace_all("c\\(\\\"    ","") %>% str_replace_all("\\\n\"","") %>% str_replace_all("\"","") %>% str_replace_all("\\)","") %>% str_replace_all("\\\\n","") %>% str_replace_all("c\\(","")
  
  
                    #Putting everything together
  
                    BPD_log <- cbind(Date, Call_taker, call_reason_action, address, police_officer, Refer_To_Summons, Summons, Refer_To_Arrest, Arrested,Age,  Occurrence_location, charges, response_time)
                     BPD_log <- data.frame(BPD_log, stringsAsFactors = FALSE)
                    BPD_log[BPD_log == "character(0"] = NA 
                    BPD_log[BPD_log == "character(0)"] = NA
                    BPD_log[BPD_log == ""] = NA 
                    BPD_log$address[is.na(BPD_log$address)] <- 0
                    for ( i in seq_along(BPD_log$Summons)){
                      
                          if(!is.na(BPD_log$Summons[i])){
                            
                            BPD_log$Arr_summ_ind[i] <- 1
                          } else
                            ifelse(!is.na(BPD_log$Summons[i]),BPD_log$Arr_summ_ind[i] <- 1,BPD_log$Arr_summ_ind[i] <- 0)
                    }
        return(BPD_log)
                  }

```

Combining daily logs into one data frame

```{r , eval= FALSE, error= FALSE}
Full_df <- df(txt_names[1])
i <- 2
while (i < length(txt_names)) {
      
      Full_df <- rbind(Full_df,df(txt_names[i])) 
      
      i = i + 1
} 

write.csv(Full_df,file = "Full_df.csv")
```

This will run after we have all the days merged
Geocoding script for large list of addresses   

Define a function that will process googles server responses for us.

```{r , eval= FALSE, error= FALSE}
Full_df$address <- as.character(Full_df$address)

Full_df$address[is.na(Full_df$address)] <- 0
getGeoDetails <- function(address){ 
     address <- as.character(address) 
   #use the gecode function to query google servers
   geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
   #now extract the bits that we need from the returned list
   answer <- data.frame(lat=NA, 
                        long=NA, 
                        accuracy=NA, 
                        formatted_address=NA, 
                        address_type=NA, 
                        status=NA)
   answer$status <- geo_reply$status

   #if we are over the query limit - want to pause for an hour
   while(geo_reply$status == "OVER_QUERY_LIMIT"){
       print("OVER QUERY LIMIT - Pausing for 1 hour at:") 
       time <- Sys.time()
       print(as.character(time))
       Sys.sleep(60*60)
       geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
       answer$status <- geo_reply$status
   }

   #return Na's if we didn't get a match:
   if (geo_reply$status != "OK"){
       return(answer)
   }   
   #else, extract what we need from the Google server reply into a dataframe:
   answer$lat <- geo_reply$results[[1]]$geometry$location$lat
   answer$long <- geo_reply$results[[1]]$geometry$location$lng   
   if (length(geo_reply$results[[1]]$types) > 0){
       answer$accuracy <- geo_reply$results[[1]]$types[[1]]
   }
   answer$address_type <- paste(geo_reply$results[[1]]$types, collapse=',')
   answer$formatted_address <- geo_reply$results[[1]]$formatted_address

   return(answer)
}

#initialise a dataframe to hold the results
geocoded <- data.frame()
# find out where to start in the address list (if the script was interrupted before):
startindex <- 1
#if a temp file exists - load it up and count the rows!
infile <- "input"
tempfilename <- paste0(infile, '_temp_geocoded.rds')
if (file.exists(tempfilename)){
       print("Found temp file - resuming from index:")
       geocoded <- readRDS(tempfilename)
       startindex <- nrow(geocoded)
       print(startindex)
}

# Start the geocoding process - address by address. geocode() function takes care of query speed limit.
for (ii in seq(startindex, length(Full_df$address))){
   print(paste("Working on index", ii, "of", length(Full_df$address)))
   #query the google geocoder - this will pause here if we are over the limit.
   result = getGeoDetails(Full_df$address[ii]) 
   print(result$status)     
   result$index <- ii
   #append the answer to the results file.
   geocoded <- rbind(geocoded, result)
   #save temporary results as we are going along
   saveRDS(geocoded, tempfilename)
}


#now we add the latitude and longitude to the main data
testdata <- Full_df[1:length(geocoded[,1]),]
testdata$lat <- geocoded$lat
testdata$long <- geocoded$long
testdata$accuracy <- geocoded$accuracy
for ( i in seq_along(testdata$Summons)){
                      
                          if(!is.na(testdata$Summons[i])){
                            
                            testdata$Arr_summ_ind[i] <- 1
                          } else{
                              if(!is.na(testdata$Summons[i])){
                                testdata$Arr_summ_ind[i] <- 1
                              } else {
                                  testdata$Arr_summ_ind[i] <- 0
                                  }
                      }
  
}


testdata$lat[testdata$lat > 42.12 | testdata$lat < 41.9] = 0 
testdata$long[testdata$long > -70.9 | testdata$long < -71.10] = 0 








write.csv(testdata,"testdata.csv")

#finally write it all to the output files
saveRDS(Full_df, paste0("../data/", infile ,"_geocoded.rds"))
write.table(data, file=paste0("../data/", infile ,"_geocoded.csv"), sep=",", row.names=FALSE)


```
Test
```{r , eval= FALSE, error= FALSE}

testdata <- read.csv("testdata.csv", stringsAsFactors = F)
testdata$coord <- paste0(testdata$lat,":",testdata$long)
testdata


testdata$Date <- as.POSIXct(testdata$Date,format ="%m/%d/%Y %H:%M") 

pal <- colorFactor(c("green", "black","red"), domain = seq(0,2, by = 1))
mymap <- leaflet(data = testdata) %>% 
  addTiles() %>% 
  setView(-71.02016, 42.08667, zoom = 13) %>% 
  addMarkers(~ long, ~ lat, popup = ~call_reason_action, clusterOptions = markerClusterOptions())
mymap

#trying to visualize patern on the frequency og calls by day
call_frequency <- hist(testdata$Date, "day", format = "%d %b", xlab = "Date", ylab = "Number of 911 Calls", main = "Call Frequency" , axis = F )


library("rpivotTable")
rpivotTable(testdata)
```


